### **Day 1: Kubernetes Cluster Setup on AWS Free Tier**

Since you're usingÂ **AWS Free Tier**, we'll set up aÂ **Kubernetes cluster usingÂ `kubeadm`Â on AWS EC2 instances**. This is the closest experience to a real-worldÂ **production-like cluster**Â while staying cost-effective.

---

## **ğŸš€ Step 1: AWS Setup - Provision EC2 Instances**

We'll create:

- **1 Master Node**Â (t3.micro, Ubuntu 22.04)
- **2 Worker Nodes**Â (t3.micro, Ubuntu 22.04)

### **1ï¸âƒ£ Create EC2 Instances**

1. Log into yourÂ **AWS Free Tier**Â account.
2. Go toÂ **EC2 Dashboard â†’ Launch Instances**.
3. ChooseÂ **Ubuntu 22.04 LTS (x86_64)**Â as the OS.
4. Select instance type:Â **t3.micro (Free Tier)**
5. Configure networking:
    - **Security Group:**Â Open portsÂ **22 (SSH), 6443 (API Server), 10250-10255 (kubelet & metrics)**
    - AllowÂ **ICMP (ping)**Â for testing.
6. **Launch 3 instances**Â (1 master, 2 workers).
7. Attach aÂ **key pair**Â for SSH access.

---

## **ğŸš€ Step 2: Connect via SSH**

Find theÂ **public IP addresses**Â of the instances.

bash
`# Connect to Master Node ssh -i your-key.pem ubuntu@<master-node-public-ip>  # Connect to Worker Nodes (in separate terminals) ssh -i your-key.pem ubuntu@<worker-node-1-ip> ssh -i your-key.pem ubuntu@<worker-node-2-ip>`

Three Nodes with one master and two worker nodes
  `ssh -i ~/.ssh/kube-keys.pem ubuntu@44.202.130.30
Â Â `ssh -i ~/.ssh/kube-keys.pem ubuntu@3.93.16.202
Â Â `ssh -i ~/.ssh/kube-keys.pem ubuntu@3.90.115.251`

---

## **ğŸš€ Step 3: Install Kubernetes & Docker on All Nodes**

Run these steps onÂ **ALL**Â nodes (Master + Workers).

### **1ï¸âƒ£ Update Packages**

bash

CopyEdit

`sudo apt update && sudo apt upgrade -y`

### **2ï¸âƒ£ Install Docker**
sudo apt update && sudo apt upgrade -y
sudo apt install -y apt-transport-https ca-certificates curl software-properties-common
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
echo "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
sudo apt update
sudo apt install -y docker-ce docker-ce-cli containerd.io
sudo systemctl enable --now docker
docker --version
sudo docker run hello-world

### **3ï¸âƒ£ Add Kubernetes Repo & Install Kubeadm, Kubectl, Kubelet**

bash

CopyEdit

`sudo apt install -y apt-transport-https ca-certificates curl 
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.29/deb/Release.key | sudo tee /etc/apt/trusted.gpg.d/kubernetes.asc echo "deb https://pkgs.k8s.io/core:/stable:/v1.29/deb/ /" | sudo tee /etc/apt/sources.list.d/kubernetes.list
sudo apt update
sudo apt install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl
kubeadm version
kubectl version --client

Verify:

bash

CopyEdit

`kubeadm version kubectl version --client`

---

## **ğŸš€ Step 4: Initialize Kubernetes on Master Node**

RunÂ **only on the Master Node**:

bash

CopyEdit

`sudo kubeadm init --pod-network-cidr=192.168.0.0/16`

After initialization,Â **copy and save the join command**Â (youâ€™ll need it for worker nodes).

### **Set Up Kubectl for Your User**

bash

CopyEdit

`mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config`

Verify:

bash

CopyEdit

`kubectl get nodes`

---

## **ğŸš€ Step 5: Apply a Network Plugin (Calico)**

bash

CopyEdit

`kubectl apply -f https://docs.projectcalico.org/manifests/calico.yaml`

Verify:

bash

CopyEdit

`kubectl get pods -n kube-system`

---

## **ğŸš€ Step 6: Join Worker Nodes**

OnÂ **each Worker Node**, run theÂ **join command**Â from Step 4.

If you forgot it, retrieve it on Master:

bash

CopyEdit

`kubeadm token create --print-join-command`

Run the output command on eachÂ **Worker Node**.

After joining, check nodes on Master:

bash

CopyEdit

`kubectl get nodes`

All nodes should showÂ **"Ready"**.

---

## **ğŸ¯ Day 1 Recap**

âœ…Â **Created a Kubernetes cluster (1 Master, 2 Workers) on AWS Free Tier**  
âœ…Â **Installed Docker, Kubernetes, and initializedÂ `kubeadm`**  
âœ…Â **Configured networking with Calico**  
âœ…Â **Successfully joined worker nodes**

---

### **Next Steps (Day 2)**

Tomorrow, weâ€™llÂ **deep dive into networking**:

- **Pod-to-Pod communication**
- **Service types (ClusterIP, NodePort, LoadBalancer)**
- **Ingress and DNS**

Let me know once you complete todayâ€™s setup! ğŸš€ğŸ’¡


To start using your cluster, you need to run the following as a regular user:

  q

Â  mkdir -p $HOME/.kube

Â  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config

Â  sudo chown $(id -u):$(id -g) $HOME/.kube/config

  

Alternatively, if you are the root user, you can run:

  

Â  export KUBECONFIG=/etc/kubernetes/admin.conf

  

You should now deploy a pod network to the cluster.

Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:

Â  https://kubernetes.io/docs/concepts/cluster-administration/addons/

  

Then you can join any number of worker nodes by running the following on each as root:

  

kubeadm join 172.31.84.44:6443 --token 0i4wbq.wfa7y1i2f3hc54j1 --discovery-token-ca-cert-hash sha256:ae1ae30c40ac9ff341add756fa75bf3bb8ab988bddc923d149f6b8f56d63fa45


ae1ae30c40ac9ff341add756fa75bf3bb8ab988bddc923d149f6b8f56d63fa45

[preflight] Running pre-flight checks

[preflight] Reading configuration from the cluster...

[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'

[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"

[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"

[kubelet-start] Starting the kubelet

[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...


Master Node: 172.31.84.44
Worker Node 1 : 172.31.38.121
Worker Node 2: 172.31.35.22

Security group policies with incoming rules are as follows:

CUSTOM TCP Port 10250 - 10250 From:0.0.0.0/0
All ICMP - IPv4 PROTOCOL:ICMP PORT:All FROM:0.0.0.0/0
IPv4 SSH PROTOCOL:TCP PORT:22 FROM:0.0.0.0/0 
IPv4 Custom TCP TCP Port:6443 From:0.0.0.0/0

Kubadm join on worked node times out with following error
```
**ubuntu@ip-172-31-38-121**:**~**$ sudo kubeadm join 172.31.84.44:6443 --token 0i4wbq.wfa7y1i2f3hc54j1 --discovery-token-ca-cert-hash sha256:ae1ae30c40ac9ff341add756fa75bf3bb8ab988bddc923d149f6b8f56d63fa45

[preflight] Running pre-flight checks

[preflight] Reading configuration from the cluster...

[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'

[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"

[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"

[kubelet-start] Starting the kubelet

[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...

[kubelet-check] Initial timeout of 40s passed.

  

Unfortunately, an error has occurred:

timed out waiting for the condition

  

This error is likely caused by:

- The kubelet is not running

- The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled)

  

If you are on a systemd-powered system, you can try to troubleshoot the error with the following commands:

- 'systemctl status kubelet'

- 'journalctl -xeu kubelet'

error execution phase kubelet-start: timed out waiting for the condition
```


Your Kubernetes control-plane has initialized successfully!

  

To start using your cluster, you need to run the following as a regular user:

  

Â  mkdir -p $HOME/.kube

Â  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config

Â  sudo chown $(id -u):$(id -g) $HOME/.kube/config

  

Alternatively, if you are the root user, you can run:

  

Â  export KUBECONFIG=/etc/kubernetes/admin.conf

  

You should now deploy a pod network to the cluster.

Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:

Â  https://kubernetes.io/docs/concepts/cluster-administration/addons/

  

Then you can join any number of worker nodes by running the following on each as root:

  

kubeadm join 172.31.16.102:6443 --token h4klmi.3ch8b67luy4nsdbn --discovery-token-ca-cert-hash sha256:fd34857d817e2080db12323e094c41a70036a8394b0e993568bc0841973c7a55